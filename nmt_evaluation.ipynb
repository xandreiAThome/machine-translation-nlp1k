{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6dedc1",
   "metadata": {},
   "source": [
    "# Neural Machine Translation Evaluation\n",
    "\n",
    "Evaluate the fine-tuned NLLB model and compare with the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd9406",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87029ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import regex as re\n",
    "\n",
    "def clean_string(input_string):\n",
    "    cleaned = re.sub(r\"[^\\p{L}\\s]\", \"\", input_string.strip().lower())\n",
    "    return cleaned\n",
    "\n",
    "def process(example):\n",
    "    src = example[\"src\"].strip()\n",
    "    tgt = example[\"tgt\"].strip()\n",
    "\n",
    "    # skip invalid pairs\n",
    "    if src.lower() == \"<no verse>\" or tgt.lower() == \"<no verse>\":\n",
    "        return {\"src\": None, \"tgt\": None}\n",
    "\n",
    "    return {\n",
    "        \"src\": clean_string(src),\n",
    "        \"tgt\": clean_string(tgt),\n",
    "    }\n",
    "\n",
    "# LANGUAGE CONFIGURATION\n",
    "SRC_LANG = \"Pangasinan\"\n",
    "TGT_LANG = \"Bikolano\"\n",
    "\n",
    "# CHECKPOINT CONFIGURATION \n",
    "CHECKPOINT_PATH = \"/kaggle/tmp/nllb-pag-bcl\"\n",
    "BASE_MODEL_NAME = \"facebook/nllb-200-distilled-600M\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_PATH)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(CHECKPOINT_PATH)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Model loaded from: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f602f",
   "metadata": {},
   "source": [
    "## Prepare Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# ===== EVALUATION DATASET CONFIGURATION =====\n",
    "EVAL_DATASET_PATH = \"/kaggle/input/bikolano-pangasinan-parallel/Bikolano_Pangasinan_Parallel.tsv\"\n",
    "\n",
    "# Load the original Bikolano-Tagalog dataset\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=EVAL_DATASET_PATH,\n",
    "    delimiter=\"\\t\",\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"].select_columns([\"Pangasinan\", \"Bikolano\"])\n",
    "dataset = dataset.rename_columns({\"Pangasinan\": \"src\", \"Bikolano\": \"tgt\"})\n",
    "\n",
    "# Apply the same cleaning function as before\n",
    "dataset = dataset.map(process)\n",
    "dataset = dataset.filter(lambda x: x[\"src\"] is not None and x[\"tgt\"] is not None)\n",
    "\n",
    "print(f\"Total dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ccae8",
   "metadata": {},
   "source": [
    "## Translation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRANSLATION FUNCTION =====\n",
    "MAX_LENGTH = 128\n",
    "GENERATION_MAX_LENGTH = 128\n",
    "NUM_BEAMS = 5\n",
    "\n",
    "def translate(text, model_tokenizer, translation_model, src_lang=SRC_LANG, tgt_lang=TGT_LANG):\n",
    "    # Tokenize input text\n",
    "    inputs = model_tokenizer(text, return_tensors=\"pt\", max_length=MAX_LENGTH, truncation=True).to(device)\n",
    "    \n",
    "    # Generate translation\n",
    "    with torch.no_grad():\n",
    "        outputs = translation_model.generate(\n",
    "            **inputs,\n",
    "            max_length=GENERATION_MAX_LENGTH,\n",
    "            num_beams=NUM_BEAMS,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    translation = model_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "print(\"Translation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22415bca",
   "metadata": {},
   "source": [
    "## Evaluate Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1493318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ===== EVALUATION CONFIGURATION =====\n",
    "EVAL_SIZE = 100\n",
    "\n",
    "# Get a sample from the dataset for evaluation\n",
    "eval_size = min(EVAL_SIZE, len(dataset))\n",
    "eval_dataset = dataset.select(range(eval_size))\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "print(f\"Generating translations for {eval_size} samples...\")\n",
    "for i, example in enumerate(tqdm(eval_dataset, total=eval_size)):\n",
    "    src_text = example[\"src\"]\n",
    "    ref_text = example[\"tgt\"]\n",
    "    \n",
    "    pred_text = translate(src_text, tokenizer, model, SRC_LANG, TGT_LANG)\n",
    "    \n",
    "    predictions.append(pred_text)\n",
    "    references.append(ref_text)\n",
    "\n",
    "def calculate_bleu(predictions, references):\n",
    "    \"\"\"Calculate corpus BLEU score\"\"\"\n",
    "    # sacrebleu expects predictions as list of strings and references as list of list of strings\n",
    "    refs = [[ref] for ref in references]\n",
    "    return sacrebleu.corpus_bleu(predictions, refs)\n",
    "\n",
    "bleu_score = calculate_bleu(predictions, references)\n",
    "print(f\"\\nFine-tuned Model BLEU Score: {bleu_score.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b6172",
   "metadata": {},
   "source": [
    "## Compare with Base NLLB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36304f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base NLLB model for comparison\n",
    "print(\"Loading base NLLB model...\")\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "base_model = base_model.to(device)\n",
    "base_model.eval()\n",
    "\n",
    "print(f\"Base model loaded: {BASE_MODEL_NAME}\")\n",
    "\n",
    "def translate_base_model(text, target_lang_code=\"tgl_Latn\", model_tokenizer=None, multilingual_model=None):\n",
    "    \"\"\" \n",
    "    Common language codes:\n",
    "        - tgl_Latn: Tagalog\n",
    "        - eng_Latn: English\n",
    "        - spa_Latn: Spanish\n",
    "        - fra_Latn: French\n",
    "        - deu_Latn: German\n",
    "        - cmn_Hans: Mandarin Chinese\n",
    "        - jpn_Jpan: Japanese\n",
    "    \"\"\"\n",
    "    if model_tokenizer is None:\n",
    "        model_tokenizer = base_tokenizer\n",
    "    if multilingual_model is None:\n",
    "        multilingual_model = base_model\n",
    "    \n",
    "    inputs = model_tokenizer(text, return_tensors=\"pt\", max_length=MAX_LENGTH, truncation=True).to(device)\n",
    "    \n",
    "    # Force the target language\n",
    "    forced_bos_token_id = model_tokenizer.convert_tokens_to_ids(target_lang_code)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = multilingual_model.generate(\n",
    "            **inputs,\n",
    "            max_length=GENERATION_MAX_LENGTH,\n",
    "            num_beams=NUM_BEAMS,\n",
    "            early_stopping=True,\n",
    "            forced_bos_token_id=forced_bos_token_id\n",
    "        )\n",
    "    \n",
    "    translation = model_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50269bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with base model\n",
    "print(\"\\nGenerating translations with base model...\")\n",
    "base_predictions = []\n",
    "\n",
    "for example in tqdm(eval_dataset, total=eval_size, desc=\"Base model\"):\n",
    "    pred_text = translate_base_model(example[\"src\"])\n",
    "    base_predictions.append(pred_text)\n",
    "\n",
    "# Calculate BLEU score for base model\n",
    "base_bleu_score = calculate_bleu(base_predictions, references)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BLEU SCORE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Base NLLB Model:        {base_bleu_score.score:.4f}\")\n",
    "print(f\"Fine-tuned Model:       {bleu_score.score:.4f}\")\n",
    "print(f\"Improvement:            {bleu_score.score - base_bleu_score.score:+.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbd820",
   "metadata": {},
   "source": [
    "## Translation Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b53e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Source (Pangasinan)\": [eval_dataset[i]['src'] for i in range(len(eval_dataset))],\n",
    "    \"Reference (Bikolano)\": references,\n",
    "    \"Base Model Output\": base_predictions,\n",
    "    \"Fine-tuned Model Output\": predictions\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"FULL TRANSLATION COMPARISON\")\n",
    "display(comparison_df.head(10))\n",
    "\n",
    "comparison_df.to_csv(\"translation_comparison.csv\", index=False)\n",
    "print(\"\\nComparison saved to: translation_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
