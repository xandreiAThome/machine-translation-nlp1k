{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae71ee49",
   "metadata": {},
   "source": [
    "# Direct Yami to Tagalog Translation Evaluation\n",
    "\n",
    "Evaluate the fine-tuned NLLB model for direct Yami → Tagalog translation using BLEU scores and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2fbad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2025.11.3)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (3.9.2)\n",
      "Requirement already satisfied: sacrebleu in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.5.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (2.9.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (4.57.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.13/site-packages (from nltk->-r requirements.txt (line 2)) (8.3.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.13/site-packages (from nltk->-r requirements.txt (line 2)) (1.5.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from nltk->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: portalocker in ./.venv/lib/python3.13/site-packages (from sacrebleu->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./.venv/lib/python3.13/site-packages (from sacrebleu->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from sacrebleu->-r requirements.txt (line 3)) (2.3.4)\n",
      "Requirement already satisfied: colorama in ./.venv/lib/python3.13/site-packages (from sacrebleu->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.13/site-packages (from sacrebleu->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (6.0.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 4)) (3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (6.0.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89483035",
   "metadata": {},
   "source": [
    "## Setup and Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7ec39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from: data/validation/yami-tgl.tsv\n",
      "Loaded 20 test pairs\n",
      "\n",
      "Columns: ['Yami', 'Tagalog']\n",
      "\n",
      "First 3 rows:\n",
      "                                                Yami  \\\n",
      "0  Ori ya kanakan ira do apheshepen, ya mamizing ...   \n",
      "1  Siciaraw ya mipangay sira do vahay, ta ya masá...   \n",
      "2  Sira kaka ira ya mivanoa do kahasan, ta somivo...   \n",
      "\n",
      "                                             Tagalog  \n",
      "0  Naroon ang mga bata sa tabing-dagat, at nakiki...  \n",
      "1  Ngayong araw ay pupunta sila sa bahay, dahil m...  \n",
      "2  Ang magkapatid ay pumunta sa kagubatan, dahil ...  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sacrebleu\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "TEST_DATA_PATH = Path(\"data/validation/yami-tgl.tsv\")\n",
    "\n",
    "print(f\"Loading test data from: {TEST_DATA_PATH}\")\n",
    "\n",
    "test_df = pd.read_csv(TEST_DATA_PATH, sep='\\t')\n",
    "\n",
    "print(f\"Loaded {len(test_df)} test pairs\")\n",
    "print(f\"\\nColumns: {test_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(test_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957872a",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee1792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Yami → Tagalog tokenizer from data/models/nllb-yami-tgl\n",
      "\n",
      "Using device: cuda\n",
      "Note: Model will be loaded when needed and unloaded after translation\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "model_yami_tgl_path = Path(\"data/models/nllb-yami-tgl\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_yami_tgl_path)\n",
    "    print(f\"Loaded Yami → Tagalog tokenizer from {model_yami_tgl_path}\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading tokenizer: {e}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "print(\"Note: Model will be loaded when needed and unloaded after translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdeea9",
   "metadata": {},
   "source": [
    "## Translation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4735ac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation functions ready (NLLB-based with explicit target language)\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "def clean_string(input_string):\n",
    "    cleaned = re.sub(r\"[^\\p{L}\\s]\", \"\", input_string.strip().lower())\n",
    "    return cleaned\n",
    "\n",
    "def translate_nllb(text, model, tokenizer, device, max_length=128, tgt_lang=\"tgl_Latn\"):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        translated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang)\n",
    "        )\n",
    "    \n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "print(\"Translation functions ready (NLLB-based with explicit target language)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049e192",
   "metadata": {},
   "source": [
    "## Perform Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "512d6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 20 valid test pairs\n",
      "\n",
      "Sample data (before and after cleaning):\n",
      "  Source (original):  Ori ya kanakan ira do apheshepen, ya mamizing sira do ciriciring ni ama ira.\n",
      "  Source (cleaned):   ori ya kanakan ira do apheshepen ya mamizing sira do ciriciring ni ama ira\n",
      "  Reference (orig):   Naroon ang mga bata sa tabing-dagat, at nakikinig sila sa mga kuwento ng kanilang ama.\n",
      "  Reference (clean):  naroon ang mga bata sa tabingdagat at nakikinig sila sa mga kuwento ng kanilang ama\n",
      "\n",
      "Loading Yami → Tagalog model...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 3.68 GiB of which 17.88 MiB is free. Process 2116 has 46.04 MiB memory in use. Process 122722 has 2.38 GiB memory in use. Including non-PyTorch memory, this process has 1.19 GiB memory in use. Of the allocated memory 1.11 GiB is allocated by PyTorch, and 15.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading Yami → Tagalog model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m model = \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_yami_tgl_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m model.eval()\n\u001b[32m     40\u001b[39m translations = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/class-code/mco/machine-translation-nlp1k/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:4343\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   4338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   4339\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4340\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4341\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4342\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/class-code/mco/machine-translation-nlp1k/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1371\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/class-code/mco/machine-translation-nlp1k/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/class-code/mco/machine-translation-nlp1k/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 930 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/class-code/mco/machine-translation-nlp1k/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/class-code/mco/machine-translation-nlp1k/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:957\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/class-code/mco/machine-translation-nlp1k/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1357\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1352\u001b[39m             device,\n\u001b[32m   1353\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1354\u001b[39m             non_blocking,\n\u001b[32m   1355\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1356\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 3.68 GiB of which 17.88 MiB is free. Process 2116 has 46.04 MiB memory in use. Process 122722 has 2.38 GiB memory in use. Including non-PyTorch memory, this process has 1.19 GiB memory in use. Of the allocated memory 1.11 GiB is allocated by PyTorch, and 15.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    src = row['Yami']\n",
    "    ref = row['Tagalog']\n",
    "    \n",
    "    if pd.isna(src) or pd.isna(ref):\n",
    "        continue\n",
    "    if str(src).lower() == '<no verse>' or str(ref).lower() == '<no verse>':\n",
    "        continue\n",
    "    \n",
    "    src_text = str(src).strip()\n",
    "    ref_text = str(ref).strip()\n",
    "    \n",
    "    if src_text and ref_text:\n",
    "        src_cleaned = clean_string(src_text)\n",
    "        ref_cleaned = clean_string(ref_text)\n",
    "        \n",
    "        test_data.append({\n",
    "            'src': src_text,\n",
    "            'src_cleaned': src_cleaned,\n",
    "            'ref': ref_text,\n",
    "            'ref_cleaned': ref_cleaned\n",
    "        })\n",
    "\n",
    "print(f\"Prepared {len(test_data)} valid test pairs\\n\")\n",
    "\n",
    "if len(test_data) > 0:\n",
    "    sample = test_data[0]\n",
    "    print(\"Sample data (before and after cleaning):\")\n",
    "    print(f\"  Source (original):  {sample['src']}\")\n",
    "    print(f\"  Source (cleaned):   {sample['src_cleaned']}\")\n",
    "    print(f\"  Reference (orig):   {sample['ref']}\")\n",
    "    print(f\"  Reference (clean):  {sample['ref_cleaned']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Loading Yami → Tagalog model...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_yami_tgl_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "translations = []\n",
    "print(\"Translating Yami text to Tagalog...\")\n",
    "for i, item in enumerate(test_data):\n",
    "    if (i + 1) % max(1, len(test_data) // 10) == 0:\n",
    "        print(f\"  Progress: {i+1}/{len(test_data)}\")\n",
    "    \n",
    "    translation = translate_nllb(\n",
    "        item['src_cleaned'],\n",
    "        model,\n",
    "        tokenizer,\n",
    "        device\n",
    "    )\n",
    "    translations.append(translation)\n",
    "\n",
    "print(\"Translation complete\")\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "references = [item['ref_cleaned'] for item in test_data]\n",
    "\n",
    "print(f\"Translated all {len(test_data)} test pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f675e",
   "metadata": {},
   "source": [
    "## Calculate BLEU Scores with SacreBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BLEU SCORE EVALUATION (using SacreBLEU with smooth method)\n",
      "======================================================================\n",
      "\n",
      "Direct Translation: Yami → Tagalog\n",
      "Test Pairs: 20\n",
      "\n",
      "Corpus BLEU Score: 2.3511\n",
      "\n",
      "BLEU Breakdown:\n",
      "  BLEU-1: 25.8555\n",
      "  BLEU-2: 5.3498\n",
      "  BLEU-3: 0.8969\n",
      "  BLEU-4: 0.2463\n",
      "  Brevity Penalty: 1.0000\n",
      "  Ratio: 1.0958\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "bleu = sacrebleu.BLEU(smooth_method='exp')\n",
    "corpus_bleu_result = bleu.corpus_score(translations, [references])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BLEU SCORE EVALUATION (using SacreBLEU with smooth method)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDirect Translation: Yami → Tagalog\")\n",
    "print(f\"Test Pairs: {len(test_data)}\")\n",
    "print(f\"\\nCorpus BLEU Score: {corpus_bleu_result.score:.4f}\")\n",
    "print(f\"\\nBLEU Breakdown:\")\n",
    "print(f\"  BLEU-1: {corpus_bleu_result.precisions[0]:.4f}\")\n",
    "print(f\"  BLEU-2: {corpus_bleu_result.precisions[1]:.4f}\")\n",
    "print(f\"  BLEU-3: {corpus_bleu_result.precisions[2]:.4f}\")\n",
    "print(f\"  BLEU-4: {corpus_bleu_result.precisions[3]:.4f}\")\n",
    "print(f\"  Brevity Penalty: {corpus_bleu_result.bp:.4f}\")\n",
    "print(f\"  Ratio: {corpus_bleu_result.ratio:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b19a9",
   "metadata": {},
   "source": [
    "## Sentence-level BLEU Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930d12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence-level BLEU Statistics:\n",
      "  Mean: 5.8927\n",
      "  Median: 4.7134\n",
      "  Min: 2.4427\n",
      "  Max: 14.4737\n",
      "  Stdev: 3.1114\n"
     ]
    }
   ],
   "source": [
    "sentence_bleu_scores = []\n",
    "bleu_sent = sacrebleu.BLEU(smooth_method='exp')\n",
    "\n",
    "for hyp, ref in zip(translations, references):\n",
    "    score = bleu_sent.sentence_score(hyp, [ref])\n",
    "    sentence_bleu_scores.append(score.score)\n",
    "\n",
    "import statistics\n",
    "\n",
    "print(f\"\\nSentence-level BLEU Statistics:\")\n",
    "print(f\"  Mean: {statistics.mean(sentence_bleu_scores):.4f}\")\n",
    "print(f\"  Median: {statistics.median(sentence_bleu_scores):.4f}\")\n",
    "print(f\"  Min: {min(sentence_bleu_scores):.4f}\")\n",
    "print(f\"  Max: {max(sentence_bleu_scores):.4f}\")\n",
    "print(f\"  Stdev: {statistics.stdev(sentence_bleu_scores) if len(sentence_bleu_scores) > 1 else 0:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25115a04",
   "metadata": {},
   "source": [
    "## Translation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73380bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORST PERFORMING TRANSLATIONS (lowest BLEU):\n",
      "\n",
      "                                                                Source (Yami)                                                         Source (Cleaned)                                                                                                  Translation (Tagalog)                                                                            Reference (Tagalog)                                                                          Reference (Cleaned)      BLEU\n",
      "6             Miangay sira do aHarang, ta rareng a mialalam ya sira do vahay.            miangay sira do aharang ta rareng a mialalam ya sira do vahay  at ang bawat isa sa kanila ay tumakas sa kanyang sariling bahay at ang bawat isa ay tumakas sa kanyang sariling bahay  Pumunta sila sa pampang, at naglaro sila malapit sa lugar kung saan nakadaong ang mga bangka.  pumunta sila sa pampang at naglaro sila malapit sa lugar kung saan nakadaong ang mga bangka  2.442663\n",
      "2      Sira kaka ira ya mivanoa do kahasan, ta somivoz sira do rarakeh no am.     sira kaka ira ya mivanoa do kahasan ta somivoz sira do rarakeh no am                            at ang lahat ng mga ito ay nahuli sa mga damo sapagkat ang mga ito ay nahuli sa mga dawagan     Ang magkapatid ay pumunta sa kagubatan, dahil pumasok sila sa malalim na bahagi ng bundok.     ang magkapatid ay pumunta sa kagubatan dahil pumasok sila sa malalim na bahagi ng bundok  2.862999\n",
      "9   Kadavayan no am ya niomahas si Kaojinzhong a, ta somivoz sira do kahasan.  kadavayan no am ya niomahas si kaojinzhong a ta somivoz sira do kahasan                                    at ang mga ito ay nagsipanggilalas at ang mga ito ay nagsipanggilalas sa mga parang             Noong mga panahong iyon, tumakas si Kaojinzhong, kaya nagtungo sila sa kabundukan.              noong mga panahong iyon tumakas si kaojinzhong kaya nagtungo sila sa kabundukan  3.125191\n",
      "15              Mamizing sira do maktokto, ya amizing pala ya misingit o tao.              mamizing sira do maktokto ya amizing pala ya misingit o tao                                        ang mga tao ay nakikinig ng mga bagay na ito at ang mga tao ay nagsipanggilalas               Nakikinig sila sa tunog ng katok; sabi nila ay may taong dahan-dahang pumapasok.                nakikinig sila sa tunog ng katok sabi nila ay may taong dahandahang pumapasok  3.218583\n",
      "10          Siciamakoyab ya mivahay sira, ta makapnezak ya misega o sozi ira.          siciamakoyab ya mivahay sira ta makapnezak ya misega o sozi ira                                    at silay nagsipanhik sa kanilang mga bahay at silay nagsipanhik sa kanilang mga paa                                  Sa hapon sila umuwi, at kinabukasan ay maaga silang gumising.                                  sa hapon sila umuwi at kinabukasan ay maaga silang gumising  3.377156\n",
      "\n",
      "======================================================================\n",
      "\n",
      "BEST PERFORMING TRANSLATIONS (highest BLEU):\n",
      "\n",
      "                                                                   Source (Yami)                                                            Source (Cleaned)                                                       Translation (Tagalog)                                                                     Reference (Tagalog)                                                                  Reference (Cleaned)       BLEU\n",
      "0   Ori ya kanakan ira do apheshepen, ya mamizing sira do ciriciring ni ama ira.  ori ya kanakan ira do apheshepen ya mamizing sira do ciriciring ni ama ira  kayat ang mga batang lalaki ay nakikinig sa kanilang ama nang araw na iyon  Naroon ang mga bata sa tabing-dagat, at nakikinig sila sa mga kuwento ng kanilang ama.  naroon ang mga bata sa tabingdagat at nakikinig sila sa mga kuwento ng kanilang ama   8.276381\n",
      "19              Simaraw ya mipangay sira do ili, ya pipangayan da o sisiawan ya.              simaraw ya mipangay sira do ili ya pipangayan da o sisiawan ya                      kinabukasan ay pumunta sila sa lunsod at silay nagutom                      Bukas ay pupunta sila sa nayon, at iyon ang kanilang patutunguhan.                     bukas ay pupunta sila sa nayon at iyon ang kanilang patutunguhan   9.080028\n",
      "17                                   “Mo makan o ya?” ya ciri ni ama do kanakan.                                     mo makan o ya ya ciri ni ama do kanakan                               kumain ka ng tinapay ng isang ama sa mga anak                                            “Kakainin mo ba ito?” tanong ng ama sa bata.                                             kakainin mo ba ito tanong ng ama sa bata   9.287529\n",
      "4               “Mamizing mo o ciriciring ni ama mo,” ya ciri ni ina do kanakan.                mamizing mo o ciriciring ni ama mo ya ciri ni ina do kanakan                     pakinggan mo ang iyong ama at ang iyong ina sa mga bata                     “Dapat makinig ka sa mga salita ng iyong ama,” sabi ng ina sa bata.                      dapat makinig ka sa mga salita ng iyong ama sabi ng ina sa bata   9.930225\n",
      "11                          Pianoodien ko o kanakan, ta amakong sira do rarakeh.                          pianoodien ko o kanakan ta amakong sira do rarakeh                 ang mga bata ay aking tinuruan na maging tulad sa matatanda               Tinawag ko ang mga bata dahil kailangan silang tumulong sa mga matatanda.             tinawag ko ang mga bata dahil kailangan silang tumulong sa mga matatanda  14.473711\n"
     ]
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Source (Yami)': [item['src'] for item in test_data],\n",
    "    'Source (Cleaned)': [item['src_cleaned'] for item in test_data],\n",
    "    'Translation (Tagalog)': translations,\n",
    "    'Reference (Tagalog)': [item['ref'] for item in test_data],\n",
    "    'Reference (Cleaned)': [item['ref_cleaned'] for item in test_data],\n",
    "    'BLEU': sentence_bleu_scores\n",
    "})\n",
    "\n",
    "comparison_df_sorted = comparison_df.sort_values('BLEU')\n",
    "\n",
    "print(\"\\nWORST PERFORMING TRANSLATIONS (lowest BLEU):\\n\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "print(comparison_df_sorted.head(5).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nBEST PERFORMING TRANSLATIONS (highest BLEU):\\n\")\n",
    "print(comparison_df_sorted.tail(5).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33785ed",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72285a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full results saved to: results/direct_yami_tgl_evaluation.csv\n",
      "Summary saved to: results/direct_yami_tgl_summary.csv\n",
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"results/direct_yami_tgl_evaluation.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "comparison_df.to_csv(output_path, index=False)\n",
    "print(f\"Full results saved to: {output_path}\")\n",
    "\n",
    "summary = {\n",
    "    'Pipeline': 'Direct: Yami → Tagalog',\n",
    "    'Test Pairs': len(test_data),\n",
    "    'Corpus BLEU': f\"{corpus_bleu_result.score:.4f}\",\n",
    "    'Mean Sentence BLEU': f\"{statistics.mean(sentence_bleu_scores):.4f}\",\n",
    "    'Median Sentence BLEU': f\"{statistics.median(sentence_bleu_scores):.4f}\",\n",
    "    'Min BLEU': f\"{min(sentence_bleu_scores):.4f}\",\n",
    "    'Max BLEU': f\"{max(sentence_bleu_scores):.4f}\",\n",
    "    'Stdev': f\"{statistics.stdev(sentence_bleu_scores) if len(sentence_bleu_scores) > 1 else 0:.4f}\",\n",
    "    'BLEU-1': f\"{corpus_bleu_result.precisions[0]:.4f}\",\n",
    "    'BLEU-2': f\"{corpus_bleu_result.precisions[1]:.4f}\",\n",
    "    'BLEU-3': f\"{corpus_bleu_result.precisions[2]:.4f}\",\n",
    "    'BLEU-4': f\"{corpus_bleu_result.precisions[3]:.4f}\",\n",
    "    'Brevity Penalty': f\"{corpus_bleu_result.bp:.4f}\"\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_path = Path(\"results/direct_yami_tgl_summary.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "\n",
    "print(f\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3093b2",
   "metadata": {},
   "source": [
    "## Evaluation on Original Bible Dataset (Tagalog_Yami_Parallel.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original bible dataset from: data/dataset/Tagalog_Yami_Parallel.tsv\n",
      "Loaded 34618 total verse pairs from bible dataset\n",
      "\n",
      "Columns: ['Book', 'Chapter', 'Verse', 'Tagalog', 'Yami']\n",
      "Unique books: 64\n",
      "\n",
      "Dataset info:\n",
      "  - Total verses: 34618\n",
      "Loaded 34618 total verse pairs from bible dataset\n",
      "\n",
      "Columns: ['Book', 'Chapter', 'Verse', 'Tagalog', 'Yami']\n",
      "Unique books: 64\n",
      "\n",
      "Dataset info:\n",
      "  - Total verses: 34618\n",
      "  - Verses with Yami translation: 11666\n",
      "  - Verses without Yami translation: 22952\n",
      "  - Verses with Yami translation: 11666\n",
      "  - Verses without Yami translation: 22952\n"
     ]
    }
   ],
   "source": [
    "bible_dataset_path = Path(\"data/dataset/Tagalog_Yami_Parallel.tsv\")\n",
    "\n",
    "print(f\"Loading original bible dataset from: {bible_dataset_path}\")\n",
    "\n",
    "bible_df = pd.read_csv(bible_dataset_path, sep='\\t')\n",
    "\n",
    "print(f\"Loaded {len(bible_df)} total verse pairs from bible dataset\")\n",
    "print(f\"\\nColumns: {bible_df.columns.tolist()}\")\n",
    "print(f\"Unique books: {bible_df['Book'].nunique()}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(f\"  - Total verses: {len(bible_df)}\")\n",
    "print(f\"  - Verses with Yami translation: {(bible_df['Yami'] != '<no verse>').sum()}\")\n",
    "print(f\"  - Verses without Yami translation: {(bible_df['Yami'] == '<no verse>').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8c203",
   "metadata": {},
   "source": [
    "### Prepare Bible Dataset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f85bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verses with both Tagalog and Yami: 11665\n",
      "Using sample of 200 verses for evaluation\n",
      "Sample includes verses from books: ['John', 'Acts', 'Romans', 'Luke', 'Mark']...\n",
      "\n",
      "Prepared 200 valid bible verse pairs\n",
      "\n",
      "Using sample of 200 verses for evaluation\n",
      "Sample includes verses from books: ['John', 'Acts', 'Romans', 'Luke', 'Mark']...\n",
      "\n",
      "Prepared 200 valid bible verse pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bible_with_yami = bible_df[(bible_df['Yami'] != '<no verse>') & (bible_df['Tagalog'] != '<no verse>')].copy()\n",
    "\n",
    "print(f\"Verses with both Tagalog and Yami: {len(bible_with_yami)}\")\n",
    "\n",
    "sample_size = min(200, len(bible_with_yami))\n",
    "bible_sample = bible_with_yami.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f\"Using sample of {len(bible_sample)} verses for evaluation\")\n",
    "print(f\"Sample includes verses from books: {bible_sample['Book'].unique()[:5].tolist()}...\")\n",
    "\n",
    "bible_test_data = []\n",
    "for idx, row in bible_sample.iterrows():\n",
    "    src = row['Yami']\n",
    "    ref = row['Tagalog']\n",
    "    \n",
    "    if pd.isna(src) or pd.isna(ref):\n",
    "        continue\n",
    "    if str(src).lower() == '<no verse>' or str(ref).lower() == '<no verse>':\n",
    "        continue\n",
    "    \n",
    "    src_text = str(src).strip()\n",
    "    ref_text = str(ref).strip()\n",
    "    \n",
    "    if src_text and ref_text:\n",
    "        src_cleaned = clean_string(src_text)\n",
    "        ref_cleaned = clean_string(ref_text)\n",
    "        \n",
    "        bible_test_data.append({\n",
    "            'book': row['Book'],\n",
    "            'chapter': row['Chapter'],\n",
    "            'verse': row['Verse'],\n",
    "            'src': src_text,\n",
    "            'src_cleaned': src_cleaned,\n",
    "            'ref': ref_text,\n",
    "            'ref_cleaned': ref_cleaned\n",
    "        })\n",
    "\n",
    "print(f\"\\nPrepared {len(bible_test_data)} valid bible verse pairs\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241df69",
   "metadata": {},
   "source": [
    "### Translate Bible Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d33500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Yami → Tagalog model for bible dataset evaluation...\n",
      "Translating 200 bible verses...\n",
      "Translating 200 bible verses...\n",
      "  Progress: 20/200\n",
      "  Progress: 20/200\n",
      "  Progress: 40/200\n",
      "  Progress: 40/200\n",
      "  Progress: 60/200\n",
      "  Progress: 60/200\n",
      "  Progress: 80/200\n",
      "  Progress: 80/200\n",
      "  Progress: 100/200\n",
      "  Progress: 100/200\n",
      "  Progress: 120/200\n",
      "  Progress: 120/200\n",
      "  Progress: 140/200\n",
      "  Progress: 140/200\n",
      "  Progress: 160/200\n",
      "  Progress: 160/200\n",
      "  Progress: 180/200\n",
      "  Progress: 180/200\n",
      "  Progress: 200/200\n",
      "  Progress: 200/200\n",
      "Bible dataset translation complete\n",
      "Translated all 200 bible verses\n",
      "Bible dataset translation complete\n",
      "Translated all 200 bible verses\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Yami → Tagalog model for bible dataset evaluation...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_yami_tgl_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "bible_translations = []\n",
    "print(f\"Translating {len(bible_test_data)} bible verses...\")\n",
    "for i, item in enumerate(bible_test_data):\n",
    "    if (i + 1) % max(1, len(bible_test_data) // 10) == 0:\n",
    "        print(f\"  Progress: {i+1}/{len(bible_test_data)}\")\n",
    "    \n",
    "    translation = translate_nllb(\n",
    "        item['src_cleaned'],\n",
    "        model,\n",
    "        tokenizer,\n",
    "        device\n",
    "    )\n",
    "    bible_translations.append(translation)\n",
    "\n",
    "print(\"Bible dataset translation complete\")\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "bible_references = [item['ref_cleaned'] for item in bible_test_data]\n",
    "\n",
    "print(f\"Translated all {len(bible_test_data)} bible verses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae80d0c",
   "metadata": {},
   "source": [
    "### Evaluate Bible Sample with BLEU Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f2342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BLEU SCORE EVALUATION - BIBLE DATASET (using SacreBLEU with smooth method)\n",
      "======================================================================\n",
      "\n",
      "Direct Translation: Yami → Tagalog (from Bible Dataset)\n",
      "Test Pairs: 200\n",
      "\n",
      "Corpus BLEU Score: 32.1611\n",
      "\n",
      "BLEU Breakdown:\n",
      "  BLEU-1: 62.0690\n",
      "  BLEU-2: 38.7779\n",
      "  BLEU-3: 27.4260\n",
      "  BLEU-4: 19.7318\n",
      "  Brevity Penalty: 0.9520\n",
      "  Ratio: 0.9531\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "bleu_bible = sacrebleu.BLEU(smooth_method='exp')\n",
    "corpus_bleu_bible = bleu_bible.corpus_score(bible_translations, [bible_references])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BLEU SCORE EVALUATION - BIBLE DATASET (using SacreBLEU with smooth method)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDirect Translation: Yami → Tagalog (from Bible Dataset)\")\n",
    "print(f\"Test Pairs: {len(bible_test_data)}\")\n",
    "print(f\"\\nCorpus BLEU Score: {corpus_bleu_bible.score:.4f}\")\n",
    "print(f\"\\nBLEU Breakdown:\")\n",
    "print(f\"  BLEU-1: {corpus_bleu_bible.precisions[0]:.4f}\")\n",
    "print(f\"  BLEU-2: {corpus_bleu_bible.precisions[1]:.4f}\")\n",
    "print(f\"  BLEU-3: {corpus_bleu_bible.precisions[2]:.4f}\")\n",
    "print(f\"  BLEU-4: {corpus_bleu_bible.precisions[3]:.4f}\")\n",
    "print(f\"  Brevity Penalty: {corpus_bleu_bible.bp:.4f}\")\n",
    "print(f\"  Ratio: {corpus_bleu_bible.ratio:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec9e7a",
   "metadata": {},
   "source": [
    "### Bible Dataset Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247590ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORST PERFORMING BIBLE VERSE TRANSLATIONS (lowest BLEU):\n",
      "\n",
      "           Book  Chapter Verse                                                                                                                                                                                                                                        Source (Yami)                                                                                                                                                                                                                                Source (Cleaned)                                                                                                                                                                                                                                           Translation (Tagalog)                                                                                                                                                                                 Reference (Tagalog)                                                                                                                                                                            Reference (Cleaned)      BLEU\n",
      "18   Colossians        1     5                                                                                                 Ta no kavavayo nyo pa nimakamizing so Mapasaray a Ciriciring na ni Ama ta do to am to nyo na nganoyngi o itoro na jinyo ni Ama ta do to do teyngato.                                                                                             ta no kavavayo nyo pa nimakamizing so mapasaray a ciriciring na ni ama ta do to am to nyo na nganoyngi o itoro na jinyo ni ama ta do to do teyngato                                                                                                                                                                                          sapagkat kayo ngay nang unang panahon na kayoy nakarinig ng ebanghelyo                                                                          dahil sa pag-asa na nakalaan para sa inyo sa langit, na inyong narinig noong una sa salita ng katotohanan, ang ebanghelyo,                                                                         dahil sa pagasa na nakalaan para sa inyo sa langit na inyong narinig noong una sa salita ng katotohanan ang ebanghelyo  1.987197\n",
      "51       Romans        1    31                                                                                                                                                                  Sya akmey yabo so nakenakem. Da alalasan o mina ciring da. Yabo pangangarilawan da.                                                                                                                                                                sya akmey yabo so nakenakem da alalasan o mina ciring da yabo pangangarilawan da                                                                                                                                                                                                                walang pagiisip walang pananalita walang pagibig                                                                                                              mga hangal, mga hindi tapat sa kanilang mga pangako, hindi mapagmahal, mga walang awa.                                                                                                             mga hangal mga hindi tapat sa kanilang mga pangako hindi mapagmahal mga walang awa  2.139538\n",
      "65      Matthew       18     7                                                      To sira makasi o tao do karawan a kalittan a meyraraten. O raraten no tao am kangay na ori. Am o tao a yapwan no kapeyraraten na am ney rako o oyaoyyan na no akman sang a tao ni Ama ta do to.                                                    to sira makasi o tao do karawan a kalittan a meyraraten o raraten no tao am kangay na ori am o tao a yapwan no kapeyraraten na am ney rako o oyaoyyan na no akman sang a tao ni ama ta do to                                                                                                                         sapagkat ang kadahilanan ng kasamaan ay lumalapit sa lahat ng mga tao datapuwat lalo pang hahatulan ang sinumang sinasaktan ng kasamaan  Kahabag-habag ang sanlibutan dahil sa mga batong katitisuran! Ang mga pangyayaring magbubunga ng pagkatisod ay tiyak na darating. Ngunit kahabag-habag ang taong pagmumulan ng batong katitisuran!  kahabaghabag ang sanlibutan dahil sa mga batong katitisuran ang mga pangyayaring magbubunga ng pagkatisod ay tiyak na darating ngunit kahabaghabag ang taong pagmumulan ng batong katitisuran  2.328130\n",
      "115       James        4     2  Nyo ikakza o karo no makadpeh jinyo. Am no yanyo jyahap am nyo naknakmen o nyo kapangap so tao. Yateywara o pangangagoman nyo am nyo kaji makahapan sya. Am ori o nyo ipeygalagalagal. Am o yanyo ji makahapi sya am nyo ji ngamya ji Ama ta do to.  nyo ikakza o karo no makadpeh jinyo am no yanyo jyahap am nyo naknakmen o nyo kapangap so tao yateywara o pangangagoman nyo am nyo kaji makahapan sya am ori o nyo ipeygalagalagal am o yanyo ji makahapi sya am nyo ji ngamya ji ama ta do to  kayoy nagnanais na magkaroon ng anuman ngunit hindi ninyo siya natagpuan kayoy nagnanais na magkaroon ng anuman ngunit hindi ninyo siya natagpuan kayoy nagnanais na magkaroon ng anuman ngunit hindi ninyo siya natagpuan sapagkat hindi ninyo siya tinanggap                 Kayo'y naghahangad, at kayo'y wala; kayo'y pumapatay at kayo'y nag-iimbot at kayo'y hindi nagkakamit. Kayo'y nag-aaway at nagdidigmaan. Kayo'y wala, sapagkat hindi kayo humihingi.                           kayoy naghahangad at kayoy wala kayoy pumapatay at kayoy nagiimbot at kayoy hindi nagkakamit kayoy nagaaway at nagdidigmaan kayoy wala sapagkat hindi kayo humihingi  2.550800\n",
      "49       Romans        4    23                                                                                                                                                                                              Am beken a iyaha o peycirngan na so kabo no raraten na.                                                                                                                                                                                          am beken a iyaha o peycirngan na so kabo no raraten na                                                                                                                                                                                                                              subalit siyay hindi naging matuwid                                                                                                                  Ngayo'y hindi lamang dahil sa kanya isinulat ang salitang, “sa kanya'y ibinilang,”                                                                                                                   ngayoy hindi lamang dahil sa kanya isinulat ang salitang sa kanyay ibinilang  2.634192\n",
      "\n",
      "======================================================================\n",
      "\n",
      "BEST PERFORMING BIBLE VERSE TRANSLATIONS (highest BLEU):\n",
      "\n",
      "       Book  Chapter Verse                                                                                                                                                          Source (Yami)                                                                                                                                                 Source (Cleaned)                                                                                                  Translation (Tagalog)                                                                                                     Reference (Tagalog)                                                                                                 Reference (Cleaned)        BLEU\n",
      "33     Mark        1     3  Amyan so tao a omlololos do kabwan no nihakawan no tao a manci no, ‘Inyo rana am wadwadan nyo o rarahan no Panirsirngen ta, ikatazineng na rana no pangonongan na.’ ”  amyan so tao a omlololos do kabwan no nihakawan no tao a manci no inyo rana am wadwadan nyo o rarahan no panirsirngen ta ikatazineng na rana no pangonongan na            ang tinig ng isang sumisigaw sa ilang ihanda ninyo ang daan ng panginoon ihanda ninyo ang kanyang mga landas     ang tinig ng isang sumisigaw sa ilang: ‘Ihanda ninyo ang daan ng Panginoon, Tuwirin ninyo ang kanyang mga landas,’”       ang tinig ng isang sumisigaw sa ilang ihanda ninyo ang daan ng panginoon tuwirin ninyo ang kanyang mga landas   84.923266\n",
      "19     Luke        3    21                                                         Teyka manaktak si Yowani so aro a tao am mai si Yeso a kataktak na jya. Meynozi si Yeso am todacyangi o hanit.                                                     teyka manaktak si yowani so aro a tao am mai si yeso a kataktak na jya meynozi si yeso am todacyangi o hanit  at nang mabautismuhan ang buong bayan at nang mabautismuhan din si jesus at siyay nananalangin ang langit ay nabuksan  Nang mabautismuhan ang buong bayan, at nang mabautismuhan din si Jesus at siya'y nananalangin, ang langit ay nabuksan.  nang mabautismuhan ang buong bayan at nang mabautismuhan din si jesus at siyay nananalangin ang langit ay nabuksan   94.261515\n",
      "103  Romans        6     7                                                                                                       Ta no mawakwak rana o tao am ji na rana nalamozongan no raraten.                                                                                                  ta no mawakwak rana o tao am ji na rana nalamozongan no raraten                                                                  sapagkat ang namatay ay pinalaya na mula sa kasalanan                                                                  sapagkat ang namatay ay pinalaya na mula sa kasalanan.                                                               sapagkat ang namatay ay pinalaya na mula sa kasalanan  100.000000\n",
      "31     Luke       23    13                              Nilovot na sira ni Pilato o panipanirsirngen no mapatanatanang so nakem da si Ama ta do to a kano kamanrarakehan da tao a kano aro a tao.                         nilovot na sira ni pilato o panipanirsirngen no mapatanatanang so nakem da si ama ta do to a kano kamanrarakehan da tao a kano aro a tao                                        at tinipon ni pilato ang mga pangulong saserdote at ang mga pinuno at ang bayan                                       At tinipon ni Pilato ang mga pangulong saserdote, at ang mga pinuno at ang bayan,                                     at tinipon ni pilato ang mga pangulong saserdote at ang mga pinuno at ang bayan  100.000000\n",
      "60     John        6    55                                                                                                  Ta o kataotao ko a kano rala ko am manoyong a kanen nyo am yopen nyo.                                                                                             ta o kataotao ko a kano rala ko am manoyong a kanen nyo am yopen nyo                                      sapagkat ang aking laman ay tunay na pagkain at ang aking dugo ay tunay na inumin                                    Sapagka't ang aking laman ay tunay na pagkain, at ang aking dugo ay tunay na inumin.                                   sapagkat ang aking laman ay tunay na pagkain at ang aking dugo ay tunay na inumin  100.000000\n"
     ]
    }
   ],
   "source": [
    "bible_comparison_df = pd.DataFrame({\n",
    "    'Book': [item['book'] for item in bible_test_data],\n",
    "    'Chapter': [item['chapter'] for item in bible_test_data],\n",
    "    'Verse': [item['verse'] for item in bible_test_data],\n",
    "    'Source (Yami)': [item['src'] for item in bible_test_data],\n",
    "    'Source (Cleaned)': [item['src_cleaned'] for item in bible_test_data],\n",
    "    'Translation (Tagalog)': bible_translations,\n",
    "    'Reference (Tagalog)': [item['ref'] for item in bible_test_data],\n",
    "    'Reference (Cleaned)': [item['ref_cleaned'] for item in bible_test_data],\n",
    "    'BLEU': bible_sentence_bleu_scores\n",
    "})\n",
    "\n",
    "bible_comparison_df_sorted = bible_comparison_df.sort_values('BLEU')\n",
    "\n",
    "print(\"\\nWORST PERFORMING BIBLE VERSE TRANSLATIONS (lowest BLEU):\\n\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "print(bible_comparison_df_sorted.head(5).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nBEST PERFORMING BIBLE VERSE TRANSLATIONS (highest BLEU):\\n\")\n",
    "print(bible_comparison_df_sorted.tail(5).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726151ec",
   "metadata": {},
   "source": [
    "### Save Bible Dataset Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbee4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full bible results saved to: results/bible_yami_tgl_evaluation.csv\n",
      "Bible summary saved to: results/bible_yami_tgl_summary.csv\n",
      "\n",
      "======================================================================\n",
      "COMPARISON: Validation Set vs Bible Dataset\n",
      "======================================================================\n",
      "                      Dataset  Test Pairs Corpus BLEU Mean BLEU  BLEU-1  BLEU-4\n",
      "Validation Set (yami-tgl.tsv)          20      2.3511    5.8927 25.8555  0.2463\n",
      "         Bible Dataset Sample         200     32.1611   29.3976 62.0690 19.7318\n",
      "\n",
      "Comparison saved to: results/yami_tgl_evaluation_comparison.csv\n",
      "\n",
      "All evaluations complete!\n"
     ]
    }
   ],
   "source": [
    "bible_output_path = Path(\"results/bible_yami_tgl_evaluation.csv\")\n",
    "bible_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bible_comparison_df.to_csv(bible_output_path, index=False)\n",
    "print(f\"Full bible results saved to: {bible_output_path}\")\n",
    "\n",
    "bible_summary = {\n",
    "    'Pipeline': 'Direct: Yami → Tagalog (Bible Dataset)',\n",
    "    'Test Pairs': len(bible_test_data),\n",
    "    'Corpus BLEU': f\"{corpus_bleu_bible.score:.4f}\",\n",
    "    'Mean Sentence BLEU': f\"{statistics.mean(bible_sentence_bleu_scores):.4f}\",\n",
    "    'Median Sentence BLEU': f\"{statistics.median(bible_sentence_bleu_scores):.4f}\",\n",
    "    'Min BLEU': f\"{min(bible_sentence_bleu_scores):.4f}\",\n",
    "    'Max BLEU': f\"{max(bible_sentence_bleu_scores):.4f}\",\n",
    "    'Stdev': f\"{statistics.stdev(bible_sentence_bleu_scores) if len(bible_sentence_bleu_scores) > 1 else 0:.4f}\",\n",
    "    'BLEU-1': f\"{corpus_bleu_bible.precisions[0]:.4f}\",\n",
    "    'BLEU-2': f\"{corpus_bleu_bible.precisions[1]:.4f}\",\n",
    "    'BLEU-3': f\"{corpus_bleu_bible.precisions[2]:.4f}\",\n",
    "    'BLEU-4': f\"{corpus_bleu_bible.precisions[3]:.4f}\",\n",
    "    'Brevity Penalty': f\"{corpus_bleu_bible.bp:.4f}\"\n",
    "}\n",
    "\n",
    "bible_summary_df = pd.DataFrame([bible_summary])\n",
    "bible_summary_path = Path(\"results/bible_yami_tgl_summary.csv\")\n",
    "bible_summary_df.to_csv(bible_summary_path, index=False)\n",
    "print(f\"Bible summary saved to: {bible_summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: Validation Set vs Bible Dataset\")\n",
    "print(\"=\"*70)\n",
    "comparison_results = pd.DataFrame([\n",
    "    {\n",
    "        'Dataset': 'Validation Set (yami-tgl.tsv)',\n",
    "        'Test Pairs': len(test_data),\n",
    "        'Corpus BLEU': f\"{corpus_bleu_result.score:.4f}\",\n",
    "        'Mean BLEU': f\"{statistics.mean(sentence_bleu_scores):.4f}\",\n",
    "        'BLEU-1': f\"{corpus_bleu_result.precisions[0]:.4f}\",\n",
    "        'BLEU-4': f\"{corpus_bleu_result.precisions[3]:.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Bible Dataset Sample',\n",
    "        'Test Pairs': len(bible_test_data),\n",
    "        'Corpus BLEU': f\"{corpus_bleu_bible.score:.4f}\",\n",
    "        'Mean BLEU': f\"{statistics.mean(bible_sentence_bleu_scores):.4f}\",\n",
    "        'BLEU-1': f\"{corpus_bleu_bible.precisions[0]:.4f}\",\n",
    "        'BLEU-4': f\"{corpus_bleu_bible.precisions[3]:.4f}\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(comparison_results.to_string(index=False))\n",
    "\n",
    "comparison_path = Path(\"results/yami_tgl_evaluation_comparison.csv\")\n",
    "comparison_results.to_csv(comparison_path, index=False)\n",
    "print(f\"\\nComparison saved to: {comparison_path}\")\n",
    "print(f\"\\nAll evaluations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a8a70",
   "metadata": {},
   "source": [
    "## Comparison with Base NLLB Model (No Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3525768",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_path = Path(\"results/model_comparison_finetuned_vs_base.csv\")\n",
    "\n",
    "if base_results_path.exists():\n",
    "    base_comparison_df = pd.read_csv(base_results_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL COMPARISON: FINE-TUNED NLLB vs BASE NLLB (No Fine-tuning)\")\n",
    "    print(\"=\"*100)\n",
    "    print(\"\\n\" + base_comparison_df.to_string(index=False))\n",
    "    \n",
    "    validation_finetuned = base_comparison_df[base_comparison_df['Scenario'].str.contains('Fine-tuned.*Validation')]['Corpus BLEU'].values[0]\n",
    "    validation_base = base_comparison_df[base_comparison_df['Scenario'].str.contains('Base NLLB.*Validation')]['Corpus BLEU'].values[0]\n",
    "    validation_improvement = ((validation_finetuned - validation_base) / validation_base) * 100\n",
    "    \n",
    "    bible_finetuned = base_comparison_df[base_comparison_df['Scenario'].str.contains('Fine-tuned.*Bible')]['Corpus BLEU'].values[0]\n",
    "    bible_base = base_comparison_df[base_comparison_df['Scenario'].str.contains('Base NLLB.*Bible')]['Corpus BLEU'].values[0]\n",
    "    bible_improvement = ((bible_finetuned - bible_base) / bible_base) * 100\n",
    "    \n",
    "    print(f\"\\n{'IMPROVEMENT ANALYSIS':^100}\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Validation Set Improvement: {validation_improvement:+.2f}% (Fine-tuned: {validation_finetuned:.4f} vs Base: {validation_base:.4f})\")\n",
    "    print(f\"Bible Dataset Improvement:  {bible_improvement:+.2f}% (Fine-tuned: {bible_finetuned:.4f} vs Base: {bible_base:.4f})\")\n",
    "    print(f\"Average Improvement:        {(validation_improvement + bible_improvement) / 2:+.2f}%\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    print(f\"\\nComparison data loaded from: {base_results_path}\")\n",
    "else:\n",
    "    print(f\"Base model comparison results not found at: {base_results_path}\")\n",
    "    print(\"Please run base_model_comparison.ipynb first to generate these results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
